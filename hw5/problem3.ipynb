{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import itertools\n",
    "from sklearn import base\n",
    "from sympy import comp\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import io\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "import base64\n",
    "\n",
    "open_ai_key = \"\"\n",
    "with open(\"key.txt\", \"r\") as file:\n",
    "    open_ai_key = file.read().strip()\n",
    "client = OpenAI(api_key=open_ai_key)\n",
    "\n",
    "base_prompt = \"Please answer the following question based on the image and the question.\\n\"\n",
    "base_prompt += \"The answer should only contain the answer type and nothing else.\\n\"\n",
    "base_prompt += \"The answer should follow the answer type of \"\n",
    "\n",
    "\n",
    "def load_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"JSON decode error: {file_path}\")\n",
    "        return None\n",
    "    return data\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Opens a JPEG image from the specified path and encodes it in Base64.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        str: Base64 encoded string of the image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the image file in binary mode\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_data = image_file.read()\n",
    "\n",
    "        # Encode the binary data to Base64\n",
    "        base64_encoded_image = base64.b64encode(image_data)\n",
    "\n",
    "        # Convert Base64 bytes to a string\n",
    "        return base64_encoded_image.decode('utf-8')\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: File not found. Please provide a valid image path.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "def prompt_llm_for_vqa(queries, images, answer_type):\n",
    "    try:\n",
    "        base64_images = []\n",
    "        for image in images:\n",
    "            base64_images.append(encode_image_to_base64(image))\n",
    "\n",
    "        complete_prompt = base_prompt + answer_type + \"\\n\"\n",
    "        complete_prompt += \"the question: \"\n",
    "        completions = []\n",
    "        for n in range(2):\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\",\n",
    "                                \"text\": complete_prompt + queries[n]},\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\"url\": f\"data:image/jpg;base64,{base64_images[n]}\"},\n",
    "                            },\n",
    "                        ],\n",
    "                    },],\n",
    "            )\n",
    "            completions.append(completion.choices[0].to_dict())\n",
    "\n",
    "        return completions\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "\n",
    "\n",
    "def save_completions_to_csv(completions, filename='results.csv'):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\n",
    "                                'question_id_one', 'question_id_two', 'answer_one', 'answer_two'])\n",
    "        writer.writeheader()\n",
    "        for completion in completions:\n",
    "            writer.writerow({\n",
    "                'question_id_one': completion['question_id_one'],\n",
    "                'question_id_two': completion['question_id_two'],\n",
    "                'answer_one': completion['answer_one'],\n",
    "                'answer_two': completion['answer_two']\n",
    "            })\n",
    "\n",
    "\n",
    "def main():\n",
    "    complementary_pairs = load_json_file(\n",
    "        \"data/v2_mscoco_val2014_complementary_pairs.json\")\n",
    "\n",
    "    if complementary_pairs is None:\n",
    "        print(\"Error loading complementary pairs file\")\n",
    "        exit(1)\n",
    "\n",
    "    questions = load_json_file(\n",
    "        \"data/v2_OpenEnded_mscoco_val2014_questions.json\")\n",
    "\n",
    "    if questions is None:\n",
    "        print(\"Error loading questions file\")\n",
    "        exit(1)\n",
    "\n",
    "    annotations = load_json_file(\n",
    "        \"data/v2_mscoco_val2014_annotations.json\")\n",
    "\n",
    "    if annotations is None:\n",
    "        print(\"Error loading annotations file\")\n",
    "        exit(1)\n",
    "\n",
    "    questions = questions[\"questions\"]\n",
    "\n",
    "    question_id_to_idx = {}\n",
    "    question_annotations = {}\n",
    "\n",
    "    # flatten complementary pairs\n",
    "    # select first 10 pairs only\n",
    "    complementary_pairs = complementary_pairs[:10]\n",
    "    complementary_pairs_flat = list(itertools.chain(*complementary_pairs))\n",
    "    # convert to hash map\n",
    "    for comp_pair in complementary_pairs_flat:\n",
    "        question_id_to_idx[comp_pair] = 1\n",
    "\n",
    "    for idx, question in enumerate(questions):\n",
    "        if question[\"question_id\"] in question_id_to_idx and question_id_to_idx[question[\"question_id\"]] == 1:\n",
    "            question_id_to_idx[question[\"question_id\"]] = idx\n",
    "\n",
    "    for idx, annotation in enumerate(annotations[\"annotations\"]):\n",
    "        if annotation[\"question_id\"] in question_id_to_idx:\n",
    "            question_annotations[annotation[\"question_id\"]] = annotation\n",
    "\n",
    "    completions = []\n",
    "    for comp_pair in complementary_pairs:\n",
    "        queries = []\n",
    "        images = []\n",
    "        answer_type = \"\"\n",
    "        for question_id in comp_pair:\n",
    "            idx = question_id_to_idx[question_id]\n",
    "            queries.append(questions[idx][\"question\"])\n",
    "            images.append(\n",
    "                f\"data/val2014/COCO_val2014_{str(questions[idx]['image_id']).zfill(12)}.jpg\")\n",
    "\n",
    "            answer_type = question_annotations[question_id][\"answer_type\"]\n",
    "\n",
    "        print(queries)\n",
    "        print(images)\n",
    "        print(answer_type)\n",
    "\n",
    "        completions.append(prompt_llm_for_vqa(queries, images, answer_type))\n",
    "\n",
    "    results = [\n",
    "        {\n",
    "            'question_id_one': comp_pair[0],\n",
    "            'question_id_two': comp_pair[1],\n",
    "            'answer_one': completions[0][\"message\"][\"content\"],\n",
    "            'answer_two': completions[1][\"message\"][\"content\"]\n",
    "        }\n",
    "        for completions, comp_pair in zip(completions, complementary_pairs)\n",
    "    ]\n",
    "\n",
    "    save_completions_to_csv(results)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
