{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whsg1XX_OZs6"
      },
      "source": [
        "# Boilerplate\n",
        "\n",
        "Package installation, loading, and dataloaders. There's also a simple model defined. You can change it your favourite architecture if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R1domTvnONqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d0aaa2-3ecb-4103-930d-7dcd4dd5d640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 22658199.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 624143.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 5573767.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2579624.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# !pip install tensorboardX\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "# from tensorboardX import SummaryWriter\n",
        "\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class ThreeLayerFC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ThreeLayerFC, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 50)\n",
        "        self.fc2 = nn.Linear(50, 50)\n",
        "        self.fc3 = nn.Linear(50, 50)\n",
        "        self.fc4 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view((-1, 28 * 28))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "    def interval_bound_propagation(self, L, U):\n",
        "        L = L.view(-1, 28 * 28)\n",
        "        U = U.view(-1, 28 * 28)\n",
        "        L_fc1 = self.fc1(L)\n",
        "        U_fc1 = self.fc1(U)\n",
        "\n",
        "        L_fc1 = F.relu(L_fc1)\n",
        "        U_fc1 = F.relu(U_fc1)\n",
        "\n",
        "        L_fc2 = self.fc2(L_fc1)\n",
        "        U_fc2 = self.fc2(U_fc1)\n",
        "\n",
        "        L_fc2 = F.relu(L_fc2)\n",
        "        U_fc2 = F.relu(U_fc2)\n",
        "\n",
        "        L_fc3 = self.fc3(L_fc2)\n",
        "        U_fc3 = self.fc3(U_fc2)\n",
        "\n",
        "        L_fc3 = F.relu(L_fc3)\n",
        "        U_fc3 = F.relu(U_fc3)\n",
        "\n",
        "        L_fc4 = self.fc4(L_fc3)\n",
        "        U_fc4 = self.fc4(U_fc3)\n",
        "\n",
        "        return L_fc4, U_fc4\n",
        "\n",
        "model = ThreeLayerFC().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mja_AB4RykO"
      },
      "source": [
        "# Implement Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xdp5H_9Pn602"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs, enable_defense=True, attack='pgd', eps=0.1):\n",
        "    # TODO: implement this function that trains a given model on the MNIST dataset.\n",
        "    # this is a general-purpose function for both standard training and adversarial training.\n",
        "    # (toggle enable_defense parameter to switch between training schemes)\n",
        "    model.train()\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    # If defense is enabled, add adversial examples to the training set\n",
        "    for epoch in range(num_epochs):\n",
        "      print(f'Epoch {epoch + 1}:')\n",
        "      correct = 0\n",
        "      total_samples = 0\n",
        "      for i, data in enumerate(train_loader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        if enable_defense:\n",
        "          inputs = pgd_untargeted(model, inputs, labels, 10, eps, 0.01)\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        cost = loss(outputs, labels)\n",
        "        cost.backward()\n",
        "\n",
        "        optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnCEpMmZKMf1"
      },
      "outputs": [],
      "source": [
        "def test_model_on_attacks(model, attack='pgd', eps=0.1):\n",
        "    # TODO: implement this function to test the robust accuracy of the given model\n",
        "    # use pgd_untargeted() within this function\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for x, y in test_loader:\n",
        "      images = pgd_untargeted(model, x, y, 10, eps, 0.01)\n",
        "      labels = y\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Robust accuracy: {(100 * correct / total):2f}%')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPMdfEhtR3zm"
      },
      "source": [
        "# Study Accuracy, Quality, etc.\n",
        "\n",
        "Compare the various results and report your observations on the submission."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model using MNIST dataset."
      ],
      "metadata": {
        "id": "TZlH2j1UUs_y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "id": "NJ90au-wKMf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7954925-3006-43d9-843b-ab2e2436e74e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Epoch 2:\n",
            "Epoch 3:\n",
            "Epoch 4:\n",
            "Epoch 5:\n"
          ]
        }
      ],
      "source": [
        "train_model(model, 5, False)\n",
        "torch.save(model.state_dict(), 'weights.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print standard accuracy"
      ],
      "metadata": {
        "id": "J6p644dYcrft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    images, labels = data\n",
        "\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    # the class with the highest energy is what we choose as prediction\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    del images, labels, outputs\n",
        "\n",
        "print(f'Standard accuracy: {100 * correct // total}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDCLds-_CvmC",
        "outputId": "1180a0b0-ff38-4750-a9e2-f968432f3512"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy: 92%\n"
          ]
        }
      ]
    },
    {
      "source": [
        "epsilons = np.linspace(0.01, 0.1, 10)\n",
        "\n",
        "total_samples = len(test_loader.dataset)\n",
        "robustness_results = torch.zeros(len(epsilons))\n",
        "model.eval()\n",
        "\n",
        "for j, epsilon in enumerate(epsilons):\n",
        "    correct_robust = 0\n",
        "\n",
        "    for i, (data, target) in enumerate(test_loader):\n",
        "        data = data.view(-1, 28, 28)  # reshape input\n",
        "        original_output = model(data).argmax(dim=1) # original prediction\n",
        "\n",
        "        # Define the lower and upper bounds for the L-infinity ball\n",
        "        L_input = torch.clamp(data - epsilon, 0, 1)\n",
        "        U_input = torch.clamp(data + epsilon, 0, 1)\n",
        "\n",
        "        L_out, U_out = model.interval_bound_propagation(L_input, U_input)\n",
        "\n",
        "        lower_bound_class = L_out.argmax(dim=1)\n",
        "        upper_bound_class = U_out.argmax(dim=1)\n",
        "\n",
        "        if (lower_bound_class == original_output).all() and (upper_bound_class == original_output).all():\n",
        "          correct_robust += 1\n",
        "\n",
        "    robustness_results[j] = correct_robust / total_samples\n",
        "    print(f\"Epsilon: {epsilon.item():.2f}, Robustness: {robustness_results[j]*100:.2f}%\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6263935-6c1b-484a-981a-8df0791c316c",
        "id": "nf8IO-owBBAT"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epsilon: 0.01, Robustness: 0.89%\n",
            "Epsilon: 0.02, Robustness: 0.54%\n",
            "Epsilon: 0.03, Robustness: 0.39%\n",
            "Epsilon: 0.04, Robustness: 0.28%\n",
            "Epsilon: 0.05, Robustness: 0.15%\n",
            "Epsilon: 0.06, Robustness: 0.12%\n",
            "Epsilon: 0.07, Robustness: 0.07%\n",
            "Epsilon: 0.08, Robustness: 0.05%\n",
            "Epsilon: 0.09, Robustness: 0.01%\n",
            "Epsilon: 0.10, Robustness: 0.01%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}